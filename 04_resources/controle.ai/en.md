## ðŸ§  Who is in control of artificial intelligence?

Three recent events reveal that the race for AGI (Artificial General Intelligence) is no longer just a technological advance - it has become a contest for power, influence and narrative. At the center of the arena are names like OpenAI, Microsoft, Anthropic, Nvidia and Google DeepMind. But the stakes go beyond technology. We are witnessing the start of a silent war over who will shape the future of artificial intelligence.

---

### âš”ï¸ The tension between OpenAI and Microsoft

The partnership between OpenAI and Microsoft - one of the most remarkable of the last decade - has begun to crack. The reason? The approach of the AGI stage and the dispute over control of what comes next.

According to the Wall Street Journal, OpenAI is considering limiting Microsoft's access to its future technologies if it reaches the AGI milestone. This would call into question the current agreement, which obliges the company to distribute its models only via the Azure platform.

Sam Altman (CEO of OpenAI) and Satya Nadella (CEO of Microsoft) have already publicly demonstrated different views. Altman believes that AGI is about to happen. Nadella, on the other hand, still sees the concept as distant and speculative.


If OpenAI declares the development of an AGI â€œsufficientâ€, it can sell or license its technologies to others - breaking the exclusivity agreement with Microsoft. This move intensifies negotiations and raises a new warning: **AGI may not be an open technology. It could be a currency of corporate power.

And this warning has been reinforced by former employees of OpenAI itself, who accuse the organization of betraying its original mission. According to them, the promise of putting security and public benefit above profit is being broken - and AGI may be being developed in an increasingly closed, volatile and financially driven environment.


---

### ðŸ”’ The silent collapse of the ethical promise

Perhaps the most disturbing news comes from within OpenAI itself. A group of former employees has issued a public warning: the organization that promised to put security and public benefit above profit is, they say, **breaking that pact**.

**The allegations include
- Abandonment of non-profit governance structures
- Reduced investment in long-term safety
- Pressure for commercial results and the launch of \â€œflashy\â€ products
- Lack of transparency and protection for whistleblowers
- Weak internal security barriers - with a real risk of leaking models such as GPT-4

If OpenAI declares the development of an AGI â€œsufficientâ€, it can sell or license its technologies to others - breaking the exclusivity agreement with Microsoft. This move intensifies negotiations and raises a new warning: **AGI may not be an open technology. It could be a currency of corporate power.

And this warning has been reinforced by former employees of OpenAI itself, who accuse the organization of betraying its original mission. According to them, the promise of putting security and public benefit above profit is being broken - and AGI may be being developed in an increasingly closed, volatile and financially driven environment.


Former security leaders, such as *Jan Leike*, and founders of OpenAI itself, such as *Ilya Sutskever*, have distanced themselves from the company and expressed doubts about Sam Altman's leadership. The lines are clear: **the original mission is being corrupted in the name of profit.**

> Former OpenAI employees are breaking their silence. And their words are not light:**
>
> ðŸ§  *"The non-profit structure was the promise of doing the right thing when the stakes were high. Now that they are, that structure is being abandoned.â€œ* - Carroll Wainwright 
> ðŸ”¥ *â€I don't think Sam (Altman) is the person who should have his finger on the AGI button."* - Ilya Sutskever, co-founder of OpenAI 
> ðŸš¨ *Mira Murati*, former CTO, also expressed discomfort with the current leadership, pointing to internal manipulations. *Tasha McCauley, a former board director, said that this behavior should be unacceptable when the security stakes are so high.

Among the strongest testimonies are also allegations of abandonment of the non-profit structure, repression of critical voices and serious internal security failures that could have exposed advanced models such as GPT-4. AGI, in this context, ceases to be a collective achievement and is treated as a strategic advantage in the hands of a few.


---

### ðŸ§¨ What's really at stake?

AGI is still a concept under construction. But the conflicts it is generating are real - and deeply human.

**We're talking about
- Concentration of power  
- Disputes over intellectual property  
- Betrayal of founding principles  
- And decisions made by a few, with an impact on billions

Former security leaders, such as Jan Leike, and founders of OpenAI itself, such as Ilya Sutskever, have distanced themselves from the company and expressed doubts about Sam Altman's leadership. The lines are clear: **the mission

> If the promise of artificial intelligence was to create a better future, the question that needs to be asked now is a different one:
>
> **Who will write the rules of the game?  
> And who will be left out of the room where they are being decided?**